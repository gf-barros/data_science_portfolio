{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import re\nimport os\n\nfrom sklearn.metrics import roc_auc_score, roc_curve, accuracy_score\nfrom sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV, RandomizedSearchCV\n\nimport matplotlib.pyplot as plt\nimport numpy as np \nimport pandas as pd \nimport xgboost as xgb\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-23T11:51:19.824108Z","iopub.execute_input":"2022-02-23T11:51:19.824724Z","iopub.status.idle":"2022-02-23T11:51:21.095917Z","shell.execute_reply.started":"2022-02-23T11:51:19.824621Z","shell.execute_reply":"2022-02-23T11:51:21.094656Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Read training and test data","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/titanic/train.csv')\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n","metadata":{"execution":{"iopub.status.busy":"2022-02-23T02:30:36.287639Z","iopub.execute_input":"2022-02-23T02:30:36.288469Z","iopub.status.idle":"2022-02-23T02:30:36.309476Z","shell.execute_reply.started":"2022-02-23T02:30:36.288409Z","shell.execute_reply":"2022-02-23T02:30:36.308428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Features preprocessing","metadata":{}},{"cell_type":"code","source":"def features_preprocessing(df):\n    \"\"\"Data preprocessing pipeline after EDA\n\n    Parameters:\n    df (pd.DataFrame): DataFrame containing raw features for training/test data.\n\n    Returns:\n    df (pd.DataFrame): DataFrame containing preprocessed features for training/test data.\n\n   \"\"\"\n    \n    df['NameTitle'] = df.Name.apply(lambda x: x.split(',')[1].split('.')[0].strip()) # Remove titles from names\n    df.loc[(df.NameTitle != \"Miss\") & (df.NameTitle != \"Mrs\") & (df.NameTitle != \"Mr\"), \"NameTitle\"] = 'None' # Remove any title different from Mr, Mrs or Miss\n    df[\"Relatives\"] = df[\"SibSp\"] + df[\"Parch\"] # Relatives count\n    df[\"RelativesCat\"] = \"Safe\"\n    df.loc[(df.Relatives == 0) | (df.Relatives >= 4), \"RelativesCat\"] = \"Unsafe\" # EDA revealed people with 0 or more than 4 relatives had low chance of survival\n    df[\"Embarked\"].fillna('S', inplace=True) # Imputation with the mode\n    df[\"Age\"].fillna(df[\"Age\"].median(), inplace=True) # Imputation with the median\n    df.Cabin.fillna('NaN', inplace=True) #Imputation with NaN\n    df[\"NumCabins\"] = df.Cabin.apply(lambda x: len(x.split(\" \"))) # Splitting the cabin number seeking relationship among letters and survival rate\n    df.loc[(df.NumCabins != 1), \"NumCabins\"] = 2\n    df[\"CabinLetters\"] = df.Cabin.apply(lambda x: re.findall(r\"^\\w\", x)[0])\n    df[\"CabinLettersCat\"] = \"Unsafe\"\n    df.loc[(df.CabinLetters.isin([\"B\", \"C\", \"E\", \"F\"])), \"CabinLettersCat\"] = \"Safe\" # EDA revealed safer sections\n    df['AgeBins'] = pd.cut(df.Age, [0,1,2,5,18,30,45,60, np.inf], include_lowest=True) # Age binning\n    df[\"FareLog\"] = np.log(df.Fare + 1) # Fare log to improve distribution\n    df['FareLogBins'] = pd.cut(df.FareLog, 6, include_lowest=True) # Fare bins\n    cols_to_drop = [\"Name\", \"Age\", \"Ticket\", \"Cabin\", \"Fare\", \"FareLogBins\", \"CabinLetters\", \"SibSp\", \"Parch\", \"Relatives\"] # Remove raw/unnecessary features\n    df = df.drop(cols_to_drop, axis=1)\n    return df\n\ndef apply_one_hot(df, cols):\n    \"\"\"One-hot encoding on categorical variables\n\n    Parameters:\n    df (pd.DataFrame): DataFrame containing preprocessed features for training/test data containing categorical variables.\n\n    Returns:\n    df (pd.DataFrame): DataFrame containing preprocessed features for training/test data containing dummy variables for each category.\n\n   \"\"\"\n    for cat in cols:\n        cat_series = df[cat]\n        cat_df = pd.get_dummies(cat_series, prefix=cat)\n        df = df.merge(\n            cat_df, how=\"left\", left_index=True, right_index=True\n        )\n    df = df.drop(cols, axis=1)\n    return df\n\ntrain_data = features_preprocessing(train_data)\ncols_to_onehot = ['Pclass', 'Sex', 'Embarked', 'NameTitle', 'CabinLettersCat', 'AgeBins', \"RelativesCat\"] # Columns requiring encoding\ntrain_data = apply_one_hot(train_data, cols_to_onehot)\ncols_to_drop = ['Pclass_3', 'Sex_male', 'Embarked_S', \"RelativesCat_Unsafe\", \"CabinLettersCat_Unsafe\"] # Redundant columns to be removed\ntrain_data = train_data.drop(cols_to_drop, axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-23T02:30:36.311950Z","iopub.execute_input":"2022-02-23T02:30:36.312710Z","iopub.status.idle":"2022-02-23T02:30:36.379457Z","shell.execute_reply.started":"2022-02-23T02:30:36.312651Z","shell.execute_reply":"2022-02-23T02:30:36.378162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"X = train_data.drop(\"Survived\", axis=1).values\ny = train_data.Survived.values\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.2, random_state=42)\n\nxg_clf = xgb.XGBClassifier(objective='reg:logistic', use_label_encoder=False)\n\nparams_grid = {'learning_rate': np.logspace(-3, -1, num=6),\n    'n_estimators': np.arange(50, 151, 10),\n    'max_depth': [2,3,4,5],\n    'subsample': np.arange(0.01, 1.01, 0.05), \n    'colsample_bytree': np.arange(0.01, 1.01, 0.05)\n}\n\nrandomized_auc = RandomizedSearchCV(estimator=xg_clf,\n    param_distributions=params_grid, \n    cv=4, \n    scoring='roc_auc',\n    verbose=1,\n    n_iter=100)\n\nrandomized_auc.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T02:30:36.381476Z","iopub.execute_input":"2022-02-23T02:30:36.381898Z","iopub.status.idle":"2022-02-23T02:31:01.343498Z","shell.execute_reply.started":"2022-02-23T02:30:36.381799Z","shell.execute_reply":"2022-02-23T02:31:01.342378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params_df = pd.DataFrame(randomized_auc.best_params_, index=[0])\nparams_df[\"score\"] = [randomized_auc.best_score_] # Visualization of the best parameters\nparams_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-23T02:31:01.344972Z","iopub.execute_input":"2022-02-23T02:31:01.345290Z","iopub.status.idle":"2022-02-23T02:31:01.370339Z","shell.execute_reply.started":"2022-02-23T02:31:01.345256Z","shell.execute_reply":"2022-02-23T02:31:01.369402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training","metadata":{}},{"cell_type":"code","source":"dtrain = xgb.DMatrix(X_train, label=y_train)\ndtest = xgb.DMatrix(X_test, label=y_test)\nparams = randomized_auc.best_params_\n\nxg_cl = xgb.XGBClassifier(\n    params=params, \n    dtrain=dtrain, \n    evals=[(dtest, \"Test\")],\n    obj='reg:tree', \n    early_stopping_rounds=7\n    )\n\nxg_cl.fit(X_train, y_train) # Fitting the classifier on the training set using the best parameters found","metadata":{"execution":{"iopub.status.busy":"2022-02-23T02:31:01.371708Z","iopub.execute_input":"2022-02-23T02:31:01.372454Z","iopub.status.idle":"2022-02-23T02:31:01.515578Z","shell.execute_reply.started":"2022-02-23T02:31:01.372395Z","shell.execute_reply":"2022-02-23T02:31:01.514333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Validation","metadata":{}},{"cell_type":"code","source":"y_pred = xg_cl.predict(X_test)\ny_pred_prob = xg_cl.predict_proba(X_test)[:,1]\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n\nplt.plot([0,1], [0,1], 'k--')\nplt.plot(fpr, tpr, label='XGBoost')\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-23T02:31:01.517876Z","iopub.execute_input":"2022-02-23T02:31:01.518390Z","iopub.status.idle":"2022-02-23T02:31:01.691703Z","shell.execute_reply.started":"2022-02-23T02:31:01.518335Z","shell.execute_reply":"2022-02-23T02:31:01.690368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inference","metadata":{}},{"cell_type":"code","source":"test_data = features_preprocessing(test_data)\ncols_to_onehot = ['Pclass', 'Sex', 'Embarked', 'NameTitle', 'CabinLettersCat', 'AgeBins', \"RelativesCat\"]\ntest_data = apply_one_hot(test_data, cols_to_onehot)\ncols_to_drop = ['Pclass_3', 'Sex_male', 'Embarked_S', \"RelativesCat_Unsafe\", \"CabinLettersCat_Unsafe\"]\ntest_data = test_data.drop(cols_to_drop, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T02:31:01.693193Z","iopub.execute_input":"2022-02-23T02:31:01.693562Z","iopub.status.idle":"2022-02-23T02:31:01.758212Z","shell.execute_reply.started":"2022-02-23T02:31:01.693522Z","shell.execute_reply":"2022-02-23T02:31:01.756709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = xg_cl.predict(test_data)\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","metadata":{"execution":{"iopub.status.busy":"2022-02-23T02:32:11.848755Z","iopub.execute_input":"2022-02-23T02:32:11.849314Z","iopub.status.idle":"2022-02-23T02:32:11.875665Z","shell.execute_reply.started":"2022-02-23T02:32:11.849259Z","shell.execute_reply":"2022-02-23T02:32:11.873996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}